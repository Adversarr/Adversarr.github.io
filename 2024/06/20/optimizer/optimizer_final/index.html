<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="Optimization Lecture 2: Convex Set Common Convex Sets  Hyperplane: \(H &#x3D; \{x \in \mathbb{R}^n \mid a^Tx &#x3D; b\}\). Halfspace: \(H &#x3D; \{x \in \mathbb{R}^n \mid a^Tx \leq b\}\). Polyhedron: \(P &#x3D; \{x \in \">
<meta property="og:type" content="article">
<meta property="og:title" content="A short summary to Optimization Theory.">
<meta property="og:url" content="https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/index.html">
<meta property="og:site_name" content="Adversarr&#39;s Blog">
<meta property="og:description" content="Optimization Lecture 2: Convex Set Common Convex Sets  Hyperplane: \(H &#x3D; \{x \in \mathbb{R}^n \mid a^Tx &#x3D; b\}\). Halfspace: \(H &#x3D; \{x \in \mathbb{R}^n \mid a^Tx \leq b\}\). Polyhedron: \(P &#x3D; \{x \in \">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-06-20T16:00:00.000Z">
<meta property="article:modified_time" content="2024-06-26T07:25:04.132Z">
<meta property="article:author" content="Adversarr">
<meta name="twitter:card" content="summary">
    
    
      
        
          <link rel="shortcut icon" href="/images/magic-wand-48.png">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/magic-wand-192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/magic-wand-180.png">
        
      
    
    <!-- title -->
    <title>A short summary to Optimization Theory.</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$'], ['\\(', '\\)']]
			}
		  });
		</script>
		<script src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js' async></script>
	
<meta name="generator" content="Hexo 7.0.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/tags/">Tag</a></li><!--
     --><!--
       --><li><a href="/categories/">Category</a></li><!--
     --><!--
       --><li><a href="/search/">Search</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/adversarr">Projects</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        
        <li><a class="icon" aria-label="Next post" href="/2024/06/18/linsys/spai/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&text=A short summary to Optimization Theory."><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&title=A short summary to Optimization Theory."><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&is_video=false&description=A short summary to Optimization Theory."><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=A short summary to Optimization Theory.&body=Check out this article: https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&title=A short summary to Optimization Theory."><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&title=A short summary to Optimization Theory."><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&title=A short summary to Optimization Theory."><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&title=A short summary to Optimization Theory."><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&name=A short summary to Optimization Theory.&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&t=A short summary to Optimization Theory."><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#optimization"><span class="toc-number">1.</span> <span class="toc-text">Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-2-convex-set"><span class="toc-number">1.1.</span> <span class="toc-text">Lecture 2: Convex Set</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#common-convex-sets"><span class="toc-number">1.1.1.</span> <span class="toc-text">Common Convex Sets</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#property-of-conv"><span class="toc-number">1.1.2.</span> <span class="toc-text">Property of conv</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#operations-on-convex-sets"><span class="toc-number">1.1.3.</span> <span class="toc-text">Operations on Convex Sets</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dual-cone-generalized-inequalities"><span class="toc-number">1.1.4.</span> <span class="toc-text">Dual Cone &amp; Generalized
Inequalities</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#separating-hyperplane-theorem"><span class="toc-number">1.1.5.</span> <span class="toc-text">Separating Hyperplane
Theorem</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-3-convex-function"><span class="toc-number">1.2.</span> <span class="toc-text">Lecture 3: Convex Function</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#gradients-hessians"><span class="toc-number">1.2.1.</span> <span class="toc-text">Gradients &amp; Hessians</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#definition"><span class="toc-number">1.2.2.</span> <span class="toc-text">Definition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#checking-convexity"><span class="toc-number">1.2.3.</span> <span class="toc-text">checking convexity</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#operations"><span class="toc-number">1.2.4.</span> <span class="toc-text">Operations</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-4-convex-problems"><span class="toc-number">1.3.</span> <span class="toc-text">Lecture 4: Convex Problems</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-5-optimal-conditions"><span class="toc-number">1.4.</span> <span class="toc-text">Lecture 5: Optimal conditions</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#first-order-condition-and-second-order-condition"><span class="toc-number">1.4.1.</span> <span class="toc-text">First Order
Condition and Second Order Condition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#duality"><span class="toc-number">1.4.2.</span> <span class="toc-text">Duality</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#optimal-condition-slater-kkt-licq"><span class="toc-number">1.4.3.</span> <span class="toc-text">Optimal condition: Slater,
KKT, LICQ</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#general-kkt-condition"><span class="toc-number">1.4.3.1.</span> <span class="toc-text">General KKT condition</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-6-gradient-descent"><span class="toc-number">1.5.</span> <span class="toc-text">Lecture 6: Gradient Descent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#more-on-convex-functions"><span class="toc-number">1.5.1.</span> <span class="toc-text">More on convex functions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#line-searching"><span class="toc-number">1.5.2.</span> <span class="toc-text">Line searching</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#non-smooth-problems"><span class="toc-number">1.5.3.</span> <span class="toc-text">Non smooth problems</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-7-subgradients"><span class="toc-number">1.6.</span> <span class="toc-text">Lecture 7: Subgradients</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#definition-of-subgradients-subdifferential"><span class="toc-number">1.6.1.</span> <span class="toc-text">Definition of
Subgradients &amp; Subdifferential</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#computing-subgradients-subdifferential"><span class="toc-number">1.6.2.</span> <span class="toc-text">Computing Subgradients
&amp; Subdifferential</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#optimal-condition"><span class="toc-number">1.6.3.</span> <span class="toc-text">Optimal condition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#subgradient-methods"><span class="toc-number">1.6.4.</span> <span class="toc-text">Subgradient methods</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-8-projected-gradient-descent-conditional-gradient-descent"><span class="toc-number">1.7.</span> <span class="toc-text">Lecture
8: projected gradient descent, conditional gradient descent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#conditional-gradient-descent"><span class="toc-number">1.7.1.</span> <span class="toc-text">Conditional Gradient Descent</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-910-proximal-mapping-proximal-gradient-descent"><span class="toc-number">1.8.</span> <span class="toc-text">Lecture
9&#x2F;10: Proximal Mapping &amp; Proximal Gradient Descent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#definition-of-proximal-mapping"><span class="toc-number">1.8.1.</span> <span class="toc-text">Definition of Proximal
Mapping</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#moreau-decomposition"><span class="toc-number">1.8.2.</span> <span class="toc-text">Moreau decomposition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#proximal-gradient-descent"><span class="toc-number">1.8.3.</span> <span class="toc-text">Proximal Gradient Descent</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#convergency"><span class="toc-number">1.8.3.1.</span> <span class="toc-text">Convergency</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#moreau-envelope"><span class="toc-number">1.8.4.</span> <span class="toc-text">Moreau Envelope</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-11-accelerated-gradient-descent"><span class="toc-number">1.9.</span> <span class="toc-text">Lecture 11: Accelerated
Gradient Descent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#fista"><span class="toc-number">1.9.1.</span> <span class="toc-text">FISTA</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-12-newtons-method"><span class="toc-number">1.10.</span> <span class="toc-text">Lecture 12: Newton’s Method</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-13-quasi-newton-methods"><span class="toc-number">1.11.</span> <span class="toc-text">Lecture 13: Quasi-Newton
Methods</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#secant-equation"><span class="toc-number">1.11.1.</span> <span class="toc-text">Secant Equation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sr1"><span class="toc-number">1.11.2.</span> <span class="toc-text">SR1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bfgs"><span class="toc-number">1.11.3.</span> <span class="toc-text">BFGS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dfp"><span class="toc-number">1.11.4.</span> <span class="toc-text">DFP</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lbfgs"><span class="toc-number">1.11.5.</span> <span class="toc-text">LBFGS</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-14-dual-ascent"><span class="toc-number">1.12.</span> <span class="toc-text">Lecture 14: Dual Ascent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#dual-proximal-gradient-accent"><span class="toc-number">1.12.1.</span> <span class="toc-text">Dual proximal gradient
accent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#min-max-problems"><span class="toc-number">1.12.2.</span> <span class="toc-text">min max problems</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-15-augmented-lagrangian"><span class="toc-number">1.13.</span> <span class="toc-text">Lecture 15: Augmented
Lagrangian</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#general-constrained-optimization"><span class="toc-number">1.13.1.</span> <span class="toc-text">General constrained
optimization</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-16-admm"><span class="toc-number">1.14.</span> <span class="toc-text">Lecture 16: ADMM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#common-techniques"><span class="toc-number">1.14.1.</span> <span class="toc-text">Common Techniques</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#douglas-rachford-splitting"><span class="toc-number">1.14.2.</span> <span class="toc-text">Douglas-Rachford Splitting</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-17-block-coordinate-descent"><span class="toc-number">1.15.</span> <span class="toc-text">Lecture 17: Block
Coordinate Descent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#coordinate-descent"><span class="toc-number">1.15.1.</span> <span class="toc-text">Coordinate Descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#block-coordinate-descent"><span class="toc-number">1.15.2.</span> <span class="toc-text">Block Coordinate Descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dual-block-coordinate-ascent"><span class="toc-number">1.15.3.</span> <span class="toc-text">Dual Block Coordinate Ascent</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-18-stochastic-optimization"><span class="toc-number">1.16.</span> <span class="toc-text">Lecture 18: Stochastic
Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#stochastic-gradient-descentsgd"><span class="toc-number">1.16.1.</span> <span class="toc-text">Stochastic Gradient
Descent(SGD)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#convergency-of-sgd"><span class="toc-number">1.16.2.</span> <span class="toc-text">Convergency of SGD</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-19-advanced-stochastic-optimization"><span class="toc-number">1.17.</span> <span class="toc-text">Lecture 19:
Advanced Stochastic Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#adagrad"><span class="toc-number">1.17.1.</span> <span class="toc-text">AdaGrad</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rmsprop"><span class="toc-number">1.17.2.</span> <span class="toc-text">RMSProp</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#adam"><span class="toc-number">1.17.3.</span> <span class="toc-text">Adam</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sag-saga"><span class="toc-number">1.17.4.</span> <span class="toc-text">SAG, SAGA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#svrg"><span class="toc-number">1.17.5.</span> <span class="toc-text">SVRG</span></a></li></ol></li></ol></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        A short summary to Optimization Theory.
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">Adversarr</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2024-06-20T16:00:00.000Z" class="dt-published" itemprop="datePublished">2024-06-21</time>
        
      
    </div>


      

      

    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <h1 id="optimization">Optimization</h1>
<h2 id="lecture-2-convex-set">Lecture 2: Convex Set</h2>
<h3 id="common-convex-sets">Common Convex Sets</h3>
<ul>
<li><strong>Hyperplane</strong>: <span class="math inline">\(H = \{x \in
\mathbb{R}^n \mid a^Tx = b\}\)</span>.</li>
<li><strong>Halfspace</strong>: <span class="math inline">\(H = \{x \in
\mathbb{R}^n \mid a^Tx \leq b\}\)</span>.</li>
<li><strong>Polyhedron</strong>: <span class="math inline">\(P = \{x \in
\mathbb{R}^n \mid Ax \leq b\}\)</span>.</li>
<li><strong>Euclidean Ball</strong>: <span class="math inline">\(B = \{x
\in \mathbb{R}^n \mid \|x - x_c\|_2 \leq r\}\)</span>.</li>
<li><strong>Ellipsoid</strong>: <span class="math inline">\(E = \{x \in
\mathbb{R}^n \mid (x - x_c)^T P^{-1} (x - x_c) \leq 1\}\)</span>.</li>
<li><strong>Norm Ball</strong>: <span class="math inline">\(B = \{x \in
\mathbb{R}^n \mid \|x - x_c\|_p \leq r\}\)</span>.</li>
<li><strong>Norm Cone</strong>: <span class="math inline">\(C = \{x \in
\mathbb{R}^n \mid \|x\|_p \leq t\}\)</span>.</li>
</ul>
<p>Some special matrices:</p>
<ul>
<li>Symmetric matrix set: <span class="math inline">\(S^n = \{X \in
\mathbb{R}^{n \times n} \mid X = X^T\}\)</span>.</li>
<li>Semi-positive definite matrix set: <span class="math inline">\(S_+^n
= \{X \in \mathbb{R}^{n \times n} \mid X = X^T, \lambda_{\min}(X) \geq
0\}\)</span>.</li>
<li>Positive definite matrix set: <span class="math inline">\(S_{++}^n =
\{X \in \mathbb{R}^{n \times n} \mid X = X^T, \lambda_{\min}(X) &gt;
0\}\)</span>.</li>
</ul>
<p>Actually, SPD matrix set is a cone.</p>
<h3 id="property-of-conv">Property of <code>conv</code></h3>
<p>Convex combination: <span class="math display">\[
x = \theta_1 x_1 + ... + \theta_k x_k, \theta_i \geq 0, \sum_{i=1}^k
\theta_i = 1.
\]</span></p>
<p><span class="math inline">\(\mathbf{conv} S\)</span> is the smallest
convex set that contains <span class="math inline">\(S\)</span>. - Also
the intersection of all convex sets that contain <span
class="math inline">\(S\)</span>.</p>
<p><code>aff</code>: The smallest affine set that contains <span
class="math inline">\(S\)</span>. - The smallest affine set that
contains <span class="math inline">\(S\)</span>. - Containing all the
affine combinations of points in <span
class="math inline">\(S\)</span>.</p>
<p>Cone: <span class="math display">\[
C = \{x \in \mathbb{R}^n \mid \lambda x \in C, \forall \lambda \geq 0\}
\]</span></p>
<p>Cone combination: <span class="math display">\[
x = \theta_1 x_1 + ... + \theta_k x_k, \theta_i \geq 0, x_i \in C.
\]</span></p>
<ul>
<li>If all the cone combinations of <span class="math inline">\(x_1,
..., x_k\)</span> are in <span class="math inline">\(C\)</span>, then
<span class="math inline">\(C\)</span> is a convex cone.</li>
</ul>
<h3 id="operations-on-convex-sets">Operations on Convex Sets</h3>
<p>Affine transform keeps convexity.</p>
<p>Perspective transform <span class="math inline">\(P: R^{n+1} \to
R^n\)</span> <span class="math display">\[
P(x, t) = \frac{x}{t}, \text{dom} P = \{(x, t) \mid t &gt; 0\}
\]</span> Perspective transform keeps convexity.</p>
<p>Therefore: <span class="math display">\[
f(x)  = \frac{Ax + b}{c^Tx + d}, \text{dom} f = \{x \mid c^Tx + d &gt;
0\}
\]</span> keeps convexity.</p>
<h3 id="dual-cone-generalized-inequalities">Dual Cone &amp; Generalized
Inequalities</h3>
<p><strong>Proper cone</strong>: - Closed - <span
class="math inline">\(\text{int} K\)</span> is nonempty - <span
class="math inline">\(K\)</span> is pointed: <span
class="math inline">\(K \cap -K = \{0\}\)</span></p>
<p>For example: 1. Nonnegative orthant: <span class="math inline">\(K =
\mathbb{R}_+^n\)</span> 2. Semi-PD matrix cone: <span
class="math inline">\(K = S_{+}^n\)</span></p>
<p><strong>Generalized Inequalities</strong>: For proper cone <span
class="math inline">\(K\)</span>, <span class="math display">\[
x \preceq_K y \Leftrightarrow y - x \in K
\]</span> Strict inequality: <span class="math display">\[
x \prec_K y \Leftrightarrow y - x \in \text{int} K
\]</span></p>
<p><strong>Dual Cone</strong>: For <span
class="math inline">\(K\)</span>, the dual cone is <span
class="math display">\[
K^* = \{y \mid x^Ty \geq 0, \forall x \in K\}
\]</span></p>
<p>There are many properties for dual cone</p>
<ul>
<li><span class="math inline">\(K^*\)</span> is a cone, and a closed
convex set.</li>
<li>if <span class="math inline">\(\mathrm{int} K\)</span> is nonempty,
then <span class="math inline">\(K^*\)</span> is pointed</li>
<li>… (see slide page 36.)</li>
</ul>
<p>One important property is: if <span class="math inline">\(K\)</span>
is proper, then <span class="math inline">\(K^*\)</span> is also
proper.</p>
<p>There is dual generalized inequalities: <span class="math display">\[
x \preceq_K y \iff y - x \in K^*
\]</span> it satisfies: - <span class="math inline">\(x \preceq_K y
\implies z^Tx \leq z^Ty, \forall z \succeq_{K^*} 0\)</span></p>
<blockquote>
<p>The advantage of dual generalized inequalities is that, the dual cone
is always closed and convex, and it converts a partial order to a full
order problem.</p>
</blockquote>
<blockquote>
<p>Reference: 02-convex-set-ustc.pdf, page 37</p>
</blockquote>
<h3 id="separating-hyperplane-theorem">Separating Hyperplane
Theorem</h3>
<p>For two disjoint convex sets <span class="math inline">\(C\)</span>
and <span class="math inline">\(D\)</span>, there exists a hyperplane
that separates them.</p>
<p><strong>Supporting Hyperplane</strong>: For a convex set <span
class="math inline">\(C\)</span>, and a point <span
class="math inline">\(x_0 \in \partial C\)</span>, there exists a
hyperplane <span class="math inline">\(a^Tx = b\)</span> such that <span
class="math inline">\(a^Tx \leq b, \forall x \in C\)</span>.</p>
<h2 id="lecture-3-convex-function">Lecture 3: Convex Function</h2>
<h3 id="gradients-hessians">Gradients &amp; Hessians</h3>
<p><strong>Gradient</strong>: <span class="math display">\[
\lim_{p\to 0} \frac{f(x + p) - f(x)}{\|p\|} = \nabla f(x)
\]</span></p>
<p><strong>Hessian</strong>: <span class="math display">\[
\nabla^2 f(x) = \begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} &amp; \frac{\partial^2 f}{\partial
x_1 \partial x_2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_1
\partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp; \frac{\partial^2
f}{\partial x_2^2} &amp; \cdots &amp; \frac{\partial^2 f}{\partial x_2
\partial x_n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} &amp; \frac{\partial^2
f}{\partial x_n \partial x_2} &amp; \cdots &amp; \frac{\partial^2
f}{\partial x_n^2}
\end{bmatrix}
\]</span></p>
<p>Gateaux derivative: <span class="math display">\[
\lim_{\alpha \to 0} \frac{f(x + \alpha d) - f(x) - t \langle g, d
\rangle}{\alpha}
\]</span></p>
<p>Some important derivatives: <span class="math display">\[
\text{Linear: } \nabla_x \mathrm{tr} (A X^T B) = BA
\]</span></p>
<p><span class="math display">\[
\text{Quadratic: } \nabla_x x^T A x = (A + A^T) x
\]</span></p>
<p><span class="math display">\[
\nabla \ln \det X = X^{-1}
\]</span></p>
<h3 id="definition">Definition</h3>
<p>A function <span class="math inline">\(f: \mathbb{R}^n \to
\mathbb{R}\)</span> is convex if: <span class="math display">\[
f(\theta x + (1-\theta)y) \leq \theta f(x) + (1-\theta)f(y), \forall x,
y \in \text{dom} f, \theta \in [0, 1]
\]</span></p>
<p>Strict convex: <span class="math display">\[
f(\theta x + (1-\theta)y) &lt; \theta f(x) + (1-\theta)f(y), \forall x,
y \in \text{dom} f, \theta \in (0, 1)
\]</span></p>
<p>some important examples in 1D: - Affines - Exponentials - Powers
<span class="math inline">\(x^p\)</span>, with <span
class="math inline">\(p \geq 1, x \in \mathbb R_{++}\)</span> - Negative
entropy <span class="math inline">\(x \ln x\)</span>, with <span
class="math inline">\(x \in \mathbb R_{++}\)</span></p>
<p>basic examples in <span class="math inline">\(\mathbb{R}^n\)</span>:
- Affine functions - Norm, with <span class="math inline">\(p \geq
1\)</span></p>
<p>In matrix space: - <span class="math inline">\(f(X) = \mathrm{tr}
(AX) = \sum_{ij} A_{ij} X_{ij} + b\)</span> is affine, convex. - Matrix
norms (<span class="math inline">\(p=2\)</span>): <span
class="math inline">\(f(X) = \|X\|_2\)</span> is convex.</p>
<h3 id="checking-convexity">checking convexity</h3>
<p><strong>Restrict to line</strong>: <span class="math inline">\(g(t) =
f(x + td)\)</span> is always convex, then <span
class="math inline">\(f\)</span> is convex.</p>
<p><strong>First order condition</strong>: if <span
class="math inline">\(f\)</span> is differentiable, then <span
class="math inline">\(f\)</span> is convex if and only if <span
class="math inline">\(f(y) \geq f(x) + \nabla f(x)^T (y -
x)\)</span>.</p>
<p>More on derivative: if <span class="math inline">\(f\)</span> is
differentiable, then <span class="math inline">\(f\)</span> is convex if
and only if <span class="math inline">\(\mathrm{dom} f\)</span> is
convex, and <span class="math inline">\(\nabla f\)</span> is
monotonically increasing: <span class="math display">\[
(\nabla f(x) - \nabla f(y))^T (x - y) \geq 0, \forall x, y \in
\text{dom} f
\]</span></p>
<p><strong>Second order condition</strong>: if <span
class="math inline">\(f\)</span> is twice differentiable, then <span
class="math inline">\(f\)</span> is convex if and only if <span
class="math inline">\(\nabla^2 f(x) \succeq 0, \forall x \in \text{dom}
f\)</span>.</p>
<p>And if <span class="math inline">\(\nabla^2 f \succ 0\)</span>, then
<span class="math inline">\(f\)</span> is strictly convex.</p>
<p><strong>Jensen’s Inequality</strong>: if <span
class="math inline">\(f\)</span> is convex, then 1. <span
class="math inline">\(f(\theta x + (1-\theta)y) \leq \theta f(x) +
(1-\theta)f(y)\)</span> 2. <span class="math inline">\(f(\mathbb{E}[X])
\leq \mathbb{E}[f(X)]\)</span></p>
<h3 id="operations">Operations</h3>
<p><strong>Nonnegative weighted sum</strong>: <span
class="math display">\[
f(x) = \sum_{i=1}^k \theta_i f_i(x), \theta_i \geq 0
\]</span></p>
<p><strong>Pointwise maximum</strong>: <span class="math display">\[
f(x) = \max_{i=1}^k f_i(x)
\]</span></p>
<p><strong>Composition with affine transform</strong>: <span
class="math display">\[
f(x) = g(Ax + b)
\]</span></p>
<p><strong>Composition with perspective transform</strong>: <span
class="math display">\[
g(x, t) = t f(x / t)
\]</span></p>
<p><strong>Conjugate function</strong>: <span class="math display">\[
f^*(y) = \sup_{x \in \text{dom} f} \langle x, y \rangle - f(x)
\]</span></p>
<ul class="task-list">
<li><label><input type="checkbox" />Connection to proximal operator,
Moreau decomposition.</label></li>
</ul>
<h2 id="lecture-4-convex-problems">Lecture 4: Convex Problems</h2>
<p><strong>Definition of Convex Optimization Problem</strong>: <span
class="math display">\[
\begin{aligned}
       \min \quad &amp;f_0(x) \\
\text{s.t.} \quad &amp;f_i(x) \leq 0, i = 1, ..., m \\
                  &amp;h_i(x) = 0, i = 1, ..., p
\end{aligned}
\]</span></p>
<p>basic property: the feasible set is convex.</p>
<p><strong>Theorem</strong>: Any local minimum of a convex problem is a
global minimum.</p>
<p><strong>Linear Programming</strong>: <span class="math display">\[
\min c^Tx \quad \text{s.t.} \quad Ax = b, G x \leq e
\]</span> and fractional linear programming, is also equivalent to
linear programming.</p>
<p><strong>Quadratic Programming</strong>: <span class="math display">\[
\min \frac{1}{2} x^T P x + q^T x + r \quad \text{s.t.} \quad Ax = b, G x
\leq e
\]</span></p>
<p>some examples: - Least squares - Stochastic Linear Programming</p>
<p><strong>QCQP</strong>: <span class="math display">\[
\min x^T P_0 x + q_0^T x + r_0 \quad \text{s.t.} \quad x^T P_i x + q_i^T
x + r_i \leq 0, i = 1, ..., m
\]</span></p>
<p><strong>SOCP</strong>: <span class="math display">\[
\begin{aligned}
       \min \quad &amp;c^Tx \\
\text{s.t.} \quad &amp;\|A_i x + b_i\|_2 \leq c_i^T x + d_i, i = 1, ...,
m
                  &amp;Fx = g
\end{aligned}
\]</span></p>
<p><strong>Convex Relaxation</strong>: max-cut: <span
class="math display">\[
\begin{aligned}
       \max \quad &amp;\frac{1}{2} \sum_{i &lt; j} (1 - x_i x_j) w_{ij}
\\
\text{s.t.} \quad &amp;x_i \in \{-1, 1\}
\end{aligned}
\]</span></p>
<p>relaxation: let <span class="math inline">\(W = (w_{ij}) \in
S^n\)</span>, <span class="math inline">\(C = -\frac{1}{4}
(\mathrm{diag} (W 1) - W)\)</span> (graph laplacian): <span
class="math display">\[
\begin{aligned}
       \max \quad &amp;\frac{1}{4} x^T C x \\
\text{s.t.} \quad &amp;x_i \in \{-1, 1\}
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(X = xx^T\)</span>, and use <span
class="math inline">\(x_i^2 = 1\)</span>, we have: <span
class="math display">\[
\begin{aligned}
       \max \quad &amp;\frac{1}{4} \mathrm{tr} (CX) \\
\text{s.t.} \quad &amp;X \succeq 0, X_{ii} = 1, X\preceq 0,
\mathrm{rank} X = 1
\end{aligned}
\]</span></p>
<h2 id="lecture-5-optimal-conditions">Lecture 5: Optimal conditions</h2>
<h3 id="first-order-condition-and-second-order-condition">First Order
Condition and Second Order Condition</h3>
<p><strong>First order</strong>: Suppose <span
class="math inline">\(f\)</span> is differentiable, then <span
class="math inline">\(x\)</span> is optimal must satisfies <span
class="math display">\[
\nabla f(x) = 0
\]</span> This is only a necessary condition generally. But for convex
function, it is also sufficient.</p>
<p><strong>Second order</strong>: Suppose <span
class="math inline">\(f\)</span> is twice differentiable, 1. necessary
condition: <span class="math inline">\(\nabla f(x) = 0, \nabla^2 f
\succeq 0\)</span> 2. sufficient condition: <span
class="math inline">\(\nabla f(x) = 0, \nabla^2 f \succ 0\)</span></p>
<h3 id="duality">Duality</h3>
<p><strong>Lagrange Dual Function</strong>: for a convex optimization
problem <span class="math display">\[
\begin{aligned}
       \min \quad &amp;f_0(x) \\
\text{s.t.} \quad &amp;f_i(x) \leq 0, i = 1, ..., m \\
                  &amp;h_i(x) = 0, i = 1, ..., p
\end{aligned}
\]</span> the Lagrange dual function is <span class="math display">\[
L(x, \lambda, \nu) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) +
\sum_{i=1}^p \nu_i h_i(x)
\]</span></p>
<p><strong>Weak Duality</strong>: for any feasible <span
class="math inline">\(x\)</span> and <span
class="math inline">\(\lambda, \nu\)</span>, <span
class="math display">\[
g(\lambda, \nu) = \inf_x L(x, \lambda, \nu)
\]</span> and, if <span class="math inline">\(\lambda \ge 0\)</span>, we
have: <span class="math display">\[
g(\lambda, \nu) \leq p^*
\]</span></p>
<p><strong>Lagrange Dual Problem</strong>: the dual problem is: <span
class="math display">\[
\begin{aligned}
       \max \quad &amp;g(\lambda, \nu) = \inf_x L(x, \lambda, \nu) \\
\text{s.t.} \quad &amp;\lambda \succeq 0
\end{aligned}
\]</span> and duality gap is <span class="math inline">\(p^* - d^* \ge
0\)</span>, where <span class="math inline">\(p^*\)</span> is the primal
optimal value, and <span class="math inline">\(d^*\)</span> is the dual
optimal value.</p>
<p>Duality feasible: <span class="math display">\[
\mathrm{dom} g = \{(\lambda, \nu) \mid \lambda \succeq 0, g(\lambda,
\nu) &gt; -\infty\}
\]</span></p>
<p>Examples: - LP -&gt; LP - QP -&gt; QP</p>
<p><strong>Connection to conjugate function</strong>: if the constraint
is linear, <span class="math display">\[
g(\lambda, \nu) = -f_0^*(-A^T \lambda - C^T \nu) - b^T \lambda - d^T \nu
\]</span> When conjugate function is known, we can directly solve the
dual problem.</p>
<p><strong>Change of variables</strong>: <span class="math display">\[
\min f_0 (Ax + b)
\]</span> can be changed to: <span class="math display">\[
\min f_0(y) \quad \text{s.t.} \quad y = Ax + b
\]</span></p>
<p><strong>Bound constrainted LP</strong>: <span class="math display">\[
\begin{aligned}
        \min &amp;c^T x \\
\text{s.t.} &amp;A x = b, -1 \le x \le 1
\end{aligned}
\]</span></p>
<p>Implicit boundary constraint: <span class="math display">\[
\begin{aligned}
        \min &amp;f_0(x) = \begin{cases}
        c^T x &amp;\text{if } -1 \le x \le 1 \\
        +\infty &amp;\text{otherwise}
    \end{cases} \\
\text{s.t.} &amp;A x = b, -1 \le x \le 1
\end{aligned}
\]</span> the dual function: <span class="math display">\[
g(\nu) = -b^T \nu - \| A^T \nu + c \|_1
\]</span></p>
<p><strong>Cones</strong>: How to deal with cone constraint? <span
class="math display">\[
\begin{aligned}
       \min &amp; f(x) \\
\text{s.t.} &amp; c_i(x) \succeq_{K_i} 0\\
            &amp; d_i(x) = 0
\end{aligned}
\]</span> the Lagrange dual function is: <span class="math display">\[
L(x, \lambda, \nu) = f(x) + \sum_i \langle \lambda_i, c_i(x)\rangle +
\sum_i \nu_i^T d_i(x)
\]</span></p>
<h3 id="optimal-condition-slater-kkt-licq">Optimal condition: Slater,
KKT, LICQ</h3>
<p>Why we need slater’s condition: wish to find the optimal condition
for a constrainted optimization problem, as if we are solving an
unconstrainted problem.</p>
<p><strong>Slater’s Condition</strong>: if there exists a feasible <span
class="math inline">\(x \in \mathrm{relint} \mathcal D\)</span> such
that <span class="math inline">\(f_i(x) &lt; 0, h_i(x) = 0\)</span>,
then we say slate’s condition holds.</p>
<p>For convex problem, Slater’s condition is sufficient for
<strong>strong duality</strong>(zero duality gap).</p>
<p><strong>KKT condition</strong>, also the <strong>First order
sufficient and necessary condition</strong>: For a convex optimization
problem, if Slater’s condition holds, then the KKT condition is
necessary and sufficient for optimality: 1. stationary: <span
class="math inline">\(0 \in \partial f(x^*) + \sum \lambda_i \partial
f_i(x^*) + \sum \nu_i \partial h_i(x^*)\)</span> 2. primal feasibility:
<span class="math inline">\(f_i(x^*) \le 0, h_i(x^*) = 0\)</span> 3.
duality feasibility: <span class="math inline">\(\lambda_i \ge
0\)</span> 4. complementary slackness: <span
class="math inline">\(\lambda_i f_i(x^*) = 0\)</span></p>
<h4 id="general-kkt-condition">General KKT condition</h4>
<p><strong>LICQ</strong>(Linear Independence Constraint Qualification):
for a point <span class="math inline">\(x\)</span>, if the gradients of
active constraints are linearly independent, then we say LICQ holds.</p>
<p>For a general problem, we need LICQ condition to ensure the KKT
condition is necessary and sufficient.</p>
<blockquote>
<p>TODO: More on LICQ</p>
</blockquote>
<ul>
<li>Analytic solution for some basic problems.</li>
</ul>
<h2 id="lecture-6-gradient-descent">Lecture 6: Gradient Descent</h2>
<p>For a quadratic problem: <span class="math display">\[
\| x_k - x^* \|^2 \le \left(\frac{\lambda_{\max} -
\lambda_{\min}}{\lambda_{\max} + \lambda_{\min}}\right) \|x_0 - x^*\|^2
\]</span></p>
<p>Therefore, we consider the Lipschitz constant: <span
class="math display">\[
\| \nabla f(x) - \nabla f(y) \| \le L \|x - y\|
\]</span> the Lipschitz constant also gives us: <span
class="math display">\[
\begin{aligned}
    f(y) &amp;\le f(x) + \nabla f(x)^T (y - x) + \frac{L}{2} \|y - x\|^2
\\
    f(x) &amp;\ge f(y) + \nabla f(y)^T (x - y) + \frac{L}{2} \|x - y\|^2
\end{aligned}
\]</span> To ensure convergence, we must set <span
class="math inline">\(\alpha_k &lt; \frac{1}{L}\)</span>.</p>
<p>Moreover, if <span class="math inline">\(f\)</span> is twice
differentiable, then <span class="math inline">\(f\)</span> is <span
class="math inline">\(m\)</span>-strong convex, and <span
class="math inline">\(L\)</span>-continuously differentiable, if: <span
class="math display">\[
m I \preceq \nabla^2 f(x) \preceq L I
\]</span></p>
<p>The convergence rate of GD is given by: <span class="math display">\[
f(x_k) - f(x^*) \le \frac{L \|x_0 - x^*\|^2}{2k}
\]</span></p>
<p>Convergence rate under strong convexity: <span
class="math display">\[
f(x^k) - f^* \le c^k \frac{L}{2} \| x^0 - x^* \|_2^2
\]</span> where <span class="math inline">\(c = L / m &lt;
1\)</span>.</p>
<h3 id="more-on-convex-functions">More on convex functions</h3>
<p>For a differentiable function, tfae: 1. <span
class="math inline">\(\nabla f\)</span> is Lipschitz continuous with
constant <span class="math inline">\(L\)</span>, 2. <span
class="math inline">\(g(x) := L/2 \|x\|_2^2 - f(x)\)</span> is convex,
3. <span class="math inline">\(\nabla f\)</span> has: <span
class="math inline">\((\nabla f(x) - \nabla f(y))^T (x - y) \ge L \|x -
y\|^2\)</span>, for all <span class="math inline">\(x, y\)</span></p>
<h3 id="line-searching">Line searching</h3>
<p><strong>Armijo rule</strong>, checking for sufficient decrease: <span
class="math display">\[
f(x_k + \alpha_k d_k) \le f(x_k) + \alpha_k c_1 \nabla f(x_k)^T d_k
\]</span></p>
<p><strong>Wolfe conditions</strong>, checking for curvature: <span
class="math display">\[
\begin{aligned}
    f(x_k + \alpha_k d_k) &amp;\le f(x_k) + \alpha_k c_1 \nabla f(x_k)^T
d_k \\
    \nabla f(x_k + \alpha_k d_k)^T d_k &amp;\ge c_2 \nabla f(x_k)^T d_k
\end{aligned}
\]</span> we need <span class="math inline">\(0 &lt; c_1 &lt; c_2 &lt;
1\)</span>.</p>
<p><strong>Goldstein conditions</strong>, a compromise between Armijo
and Wolfe: <span class="math display">\[
\begin{aligned}
    f(x_k + \alpha_k d_k) &amp;\le f(x_k) + \alpha_k c_1 \nabla f(x_k)^T
d_k \\
    f(x_k + \alpha_k d_k) &amp;\ge f(x_k) + \alpha_k (1-c) \nabla
f(x_k)^T d_k
\end{aligned}
\]</span> we need <span class="math inline">\(0 &lt; c &lt;
1/2\)</span></p>
<h3 id="non-smooth-problems">Non smooth problems</h3>
<p>Convergence rate for gd: <span class="math display">\[
\min _{k = 0, 1, ..., T} \| \nabla f (x_k) \|^2 \le \frac{2 L (f(x_0) -
f^*)}{T}
\]</span></p>
<p>TODO: Check for the convergency proof.</p>
<h2 id="lecture-7-subgradients">Lecture 7: Subgradients</h2>
<h3 id="definition-of-subgradients-subdifferential">Definition of
Subgradients &amp; Subdifferential</h3>
<p><strong>Subgradient</strong>: <span class="math display">\[
\partial f(x) = \{ g \mid f(y) \ge f(x) + g^T (y - x), \forall y \}
\]</span></p>
<p>For a convex function, <span class="math inline">\(x \in
\mathrm{int~dom} f\)</span>, the subgradient is always nonempty.</p>
<h3 id="computing-subgradients-subdifferential">Computing Subgradients
&amp; Subdifferential</h3>
<p>differentiable function: equivalent to strong derivative.</p>
<p>Non-negative weighted sum.</p>
<p>Composition with affine transform.</p>
<p>Pointwise maximum: <span class="math display">\[
f(x) = \max \{ f_1(x), f_2(x) \}
\implies
\partial f(x) = \mathbf{conv} \partial f_1(x) \cup \partial f_2(x)
\]</span></p>
<p>Examples: - Piecewise linear function - L1 norm.</p>
<h3 id="optimal-condition">Optimal condition</h3>
<p><strong>First order condition</strong>(unconstrainted): <span
class="math inline">\(x^*\)</span> is local minimum, if and only if,
<span class="math display">\[
0 \in \partial f
\]</span></p>
<p><strong>First order condition</strong>(constrainted): <span
class="math inline">\(x^*\)</span> is local minimum, if and only if,
<span class="math display">\[
0 \in \partial f(x^*) + \sum \lambda_i \partial f_i(x^*)
\]</span> where <span class="math inline">\(\lambda_i \ge 0\)</span> is
the optimal dual variable.</p>
<h3 id="subgradient-methods">Subgradient methods</h3>
<p><span class="math display">\[
x^{k+1}\larr x^k - \alpha_k g^k
\]</span> we have many choices for <span
class="math inline">\(\alpha_k\)</span>: 1. constant step size: does not
guarantee convergency 2. constant <span class="math inline">\(\|x^{k+1}
- x^k\|\)</span>: does not guarantee convergency 3. diminishing step
size: ok, a typical choice is <span class="math inline">\(\alpha_k =
1/k\)</span> 4. line search: ok, but expensive.</p>
<h2
id="lecture-8-projected-gradient-descent-conditional-gradient-descent">Lecture
8: projected gradient descent, conditional gradient descent</h2>
<p>Now consider constrainted problems.</p>
<p><strong>Optimal condition</strong>: <span class="math display">\[
\langle \nabla f(x^*), x^* - y\rangle = 0,\quad \forall y in C
\]</span></p>
<p><strong>Projected Gradient Descent</strong>: <span
class="math display">\[
x_{k+1} = \Pi_C (x_k - \alpha_k \nabla f(x_k))
\]</span></p>
<p><strong>Non expansion property of projection</strong>: if <span
class="math inline">\(C\)</span> is convex, <span
class="math display">\[
\| \Pi_C(x) - \Pi_C(y) \| \le \|x - y\|
\]</span></p>
<p>The convergency result under strong convex assumption: <span
class="math display">\[
\|x_k - x^*\|^2 \leq \left(1 - \frac{m}{L}\right)^k \|x_0 - x^*\|^2
\]</span> if we choose <span class="math inline">\(\alpha_k =
1/L\)</span></p>
<h3 id="conditional-gradient-descent">Conditional Gradient Descent</h3>
<p>also called Frank-Wolfe algorithm.</p>
<p>Why we need conditional gradient descent: Projection is expensive</p>
<p><strong>Conditional Gradient Descent</strong>: <span
class="math display">\[
\begin{aligned}
    x_k &amp;= \arg\min_{x \in C} \langle \nabla f(x_{k-1}), x \rangle,
\\
    y_k &amp;= y_{k-1} + \alpha_k (x_k - y_{k-1})
\end{aligned}
\]</span> might be easier, if the linear programming is easy in <span
class="math inline">\(C\)</span></p>
<p>Choices for <span class="math inline">\(\alpha_k\)</span>: -
diminishing step size: <span class="math inline">\(\alpha_k =
2/(k+1)\)</span> - or via exact line search</p>
<h2 id="lecture-910-proximal-mapping-proximal-gradient-descent">Lecture
9/10: Proximal Mapping &amp; Proximal Gradient Descent</h2>
<h3 id="definition-of-proximal-mapping">Definition of Proximal
Mapping</h3>
<p><strong>Proximal Mapping</strong>: <span class="math display">\[
\text{prox}_{\alpha f}(x) = \arg\min_y \left( f(y) + \frac{1}{2} \|y -
x\|^2 \right)
\]</span></p>
<p><strong>Relation to subgradient</strong>: <span
class="math display">\[
u = \text{prox}_{f}(x) \iff x - u \in \partial f(u)
\]</span></p>
<p><strong>Relation to projection</strong>: <span
class="math display">\[
\text{prox}_{I_C}(x) = \Pi_C(x)
\]</span></p>
<h3 id="moreau-decomposition">Moreau decomposition</h3>
<p><span class="math display">\[
x = \mathrm{prox}_{h}(x) + \mathrm{prox}_{h^*}(x)
\]</span> Generally: <span class="math display">\[
x = \mathrm{prox}_{\lambda h}(x) +
\lambda\mathrm{prox}_{\lambda^{-1}h^*}(x)
\]</span></p>
<p>we can use Moreau decomposition to compute many proximal
mappings.</p>
<p><strong>Norm Ball</strong>: The conjugate of <span
class="math inline">\(\| \cdot \|\)</span> is the indicator function of
the unit ball under the dual norm.</p>
<p><span class="math display">\[
\text{prox}_{\alpha \| \cdot \|}(x) = x - \alpha \Pi_{\| \cdot \|}(x /
\alpha) = x - \Pi_{t\| \cdot \|}(x)
\]</span></p>
<h3 id="proximal-gradient-descent">Proximal Gradient Descent</h3>
<p><strong>Proximal Gradient Descent</strong>: <span
class="math display">\[
x_{k+1} = \text{prox}_{\alpha h}(x_k - \alpha \nabla f(x_k))
\]</span></p>
<p>due to the optimal condition, we have: <span class="math display">\[
x = \text{prox}_{\alpha h}(x - \alpha \nabla f(x)) \iff -\nabla f(x) \in
\partial h(x)
\]</span></p>
<h4 id="convergency">Convergency</h4>
<p>Define the gradient mapping: <span class="math display">\[
G_t (x) = \frac{1}{t} (x - \text{prox}_{t h}(x - t \nabla f(x)))
\]</span></p>
<p>The proximal gradient descent can be written as: <span
class="math display">\[
x_{k+1} = x_k - t G_{\alpha} (x_k)
\]</span></p>
<p>Convergency for constant step size <span class="math inline">\(\alpha
&lt; 1/L\)</span>: <span class="math display">\[
f(x_k) - f(x^*) \le \frac{2 L}{k}\|x_0 - x^*\|^2
\]</span></p>
<p>Convergency for backtracking, similar. <span class="math display">\[
f(x_k) - f(x^*) \le \frac{1}{2k \min\{ \hat{t}, \beta/L \}} \|x_0 -
x^*\|^2
\]</span></p>
<h3 id="moreau-envelope">Moreau Envelope</h3>
<p><strong>Moreau Envelope</strong>: <span class="math display">\[
h_\alpha (x) = \min_y h(y) + \frac{1}{2\alpha} \|x - y\|^2
\]</span></p>
<p>Moreau envelop can be viewed as an approximation to non smooth <span
class="math inline">\(h\)</span>.</p>
<p>For any proper, closed, convex function, the Moreau envelop <span
class="math inline">\(h_\alpha\)</span> is differentiable, and the
gradient is given by: <span class="math display">\[
\nabla h_\alpha (x) = \frac{1}{\alpha} (x - \text{prox}_{\alpha h}(x))
\]</span></p>
<h2 id="lecture-11-accelerated-gradient-descent">Lecture 11: Accelerated
Gradient Descent</h2>
<p><strong>Heavy ball method</strong>(Polyak, 1964), also called
momentum method: <span class="math display">\[
x_{k+1} = x_k - \eta \nabla f(x_k) + \beta (x_k - x_{k-1})
\]</span></p>
<p><strong>Nesterov’s accelerated gradient descent</strong>(1983): <span
class="math display">\[
\begin{aligned}
    y_k &amp;= x_k + \frac{k-1}{k+2} (x_k - x_{k-1}) \\
    x_{k+1} &amp;= y_k - \eta \nabla f(y_k)
\end{aligned}
\]</span> convergency rate, let <span class="math inline">\(s =
1/L\)</span>: <span class="math display">\[
f(x_k) - f^* \leq \frac{2L \|x_0 - x^*\|^2}{(k+1)^2}
\]</span> complexity is <span
class="math inline">\(O(\frac{1}{\epsilon}^{1/2})\)</span>, much faster
than GD, which is <span
class="math inline">\(O(\frac{1}{\epsilon})\)</span>.</p>
<h3 id="fista">FISTA</h3>
<p><strong>FISTA</strong>(Beck and Teboulle, 2009): <span
class="math display">\[
\begin{aligned}
    y_k &amp;= x_k + \frac{k-1}{k+2} (x_k - x_{k-1}) \\
    x_{k+1} &amp;= \text{prox}_{\eta h} (y_k - \eta \nabla f(y_k))
\end{aligned}
\]</span> only changed the gradient update rule to proximal mapping.</p>
<p>Convergency rate: suppose strong convexity, <span
class="math inline">\(\kappa = L / \mu\)</span> <span
class="math display">\[
f(x_k) - f^* \leq \left( 1 - \frac{1}{\sqrt{\kappa}} \right) ^k (f(x_0)
- f^* + \mu \|x_0 - x^*\|^2 / 2)
\]</span> complexity: <span class="math inline">\(O(\kappa
\log(1/\epsilon))\)</span></p>
<h2 id="lecture-12-newtons-method">Lecture 12: Newton’s Method</h2>
<p><strong>Newton’s Method</strong>: for a twice differentiable
function, the update rule is: <span class="math display">\[
x_{k+1} = x_k - \nabla^2 f(x_k)^{-1} \nabla f(x_k)
\]</span></p>
<p>Affine invariance: Newton’s method is invariant under affine
transformation.</p>
<p>Convergence: if <span class="math inline">\(f\)</span> is strongly
convex, then Newton’s method converges quadratically.</p>
<p><strong>Modified Newton’s Method</strong>: for non-convex problem, we
can use modified Newton’s method: <span class="math display">\[
x_{k+1} = x_k - \alpha \hat{H}^{-1} \nabla f(x_k)
\]</span> the Hessian is approximated by <span
class="math inline">\(\hat{H}\)</span>, and <span
class="math inline">\(\alpha\)</span> is the step size from line
search.</p>
<p>Requirement on <span class="math inline">\(\hat{H}\)</span>: 1. <span
class="math inline">\(\hat{H}\)</span> is positive definite 2. <span
class="math inline">\(\hat{H}\)</span> is close to the true Hessian 3.
<span class="math inline">\(\hat{H}\)</span> has small condition
number</p>
<p><strong>Inexact Newton’s Method</strong>: for large scale problem, we
can use inexact Newton’s method: - use iterative method to solve <span
class="math inline">\(\hat{H} \delta = -\nabla f(x_k)\)</span> - stop
early, when <span class="math inline">\(\|\hat{H} \delta + \nabla
f(x_k)\|\)</span> is small enough.</p>
<p><strong>Linesearch Newton-CG</strong>: replace the iterative method
with Conjugate Gradient.</p>
<h2 id="lecture-13-quasi-newton-methods">Lecture 13: Quasi-Newton
Methods</h2>
<h3 id="secant-equation">Secant Equation</h3>
<p><span class="math display">\[
B_{k+1} s_k = y_k
\]</span> where <span class="math inline">\(B_k\)</span> is the
approximation of the Hessian. and <span class="math inline">\(H_{k+1} =
B_{k+1}^{-1}\)</span> is the approximation of the inverse Hessian. <span
class="math display">\[
H_{k+1} y_k = s_k
\]</span> where <span class="math inline">\(y_k = \nabla f(x_{k+1}) -
\nabla f(x_k)\)</span>, and <span class="math inline">\(s_k = x_{k+1} -
x_k\)</span>.</p>
<p><strong>Curvature requirement</strong>: <span class="math display">\[
y_k^T s_k &gt; 0
\]</span> We need to use Wolfe condition in line search.</p>
<h3 id="sr1">SR1</h3>
<p><strong>SR1</strong>: Rank 1 update, <span
class="math inline">\(B_{k+1} = B_k + a uu^T\)</span>, where 1. <span
class="math inline">\(u = y_k - B_k s_k\)</span>. 2. <span
class="math inline">\(a = 1 / u^T s_k\)</span>.</p>
<p>Drawback: SR1 does not guarantee positive definiteness. A sufficient
condition for PD is: 1. <span class="math inline">\(B^k\)</span> is PD,
2. <span class="math inline">\(u^T s_k &gt; 0\)</span>.</p>
<h3 id="bfgs">BFGS</h3>
<p><strong>BFGS</strong>: Rank 2 update. <span class="math display">\[
B_{k+1} = B_k + a u u^T + b v v^T
\]</span></p>
<p>Then we have: <span class="math display">\[
(a \cdot u^T s_k) u + (b \cdot v^T s_k) v = y_k - B_k s_k
\]</span> therefore: <span class="math display">\[
B_{k+1} = B_k + \frac{y_k y_k^T}{y_k^T s_k} - \frac{B_k s_k s_k^T
B_k^T}{s_k^T B_k s_k}
\]</span> and <span class="math display">\[
H_{k+1} = \left( I - \frac{s_k y_k^T}{y_k^T s_k} \right) H_k \left( I -
\frac{y_k s_k^T}{y_k^T s_k} \right) + \frac{s_k s_k^T}{y_k^T s_k}
\]</span></p>
<blockquote>
<p><strong>Sherman-Morrison formula</strong>: <span
class="math display">\[(A + uv^T)^{-1} = A^{-1} - \frac{A^{-1} u v^T
A^{-1}}{1 + v^T A^{-1} u}\]</span></p>
</blockquote>
<p><strong>Positive definiteness requirement</strong>: 1. <span
class="math inline">\(B_k\)</span> or <span
class="math inline">\(H_k\)</span> is PD 2. curvature requirement is
satsfied <span class="math inline">\(y_k^T s_k &gt; 0\)</span></p>
<h3 id="dfp">DFP</h3>
<p><strong>DFP</strong>: <span class="math display">\[
B_{k+1} = B_k - \frac{B_k s_k s_k^T B_k}{s_k^T B_k s_k} + \frac{y_k
y_k^T}{y_k^T s_k}
\]</span></p>
<h3 id="lbfgs">LBFGS</h3>
<p>use two-loop recursion to replace the inverse Hessian.</p>
<h2 id="lecture-14-dual-ascent">Lecture 14: Dual Ascent</h2>
<blockquote>
<p>Drawback for primal methods:</p>
<ol type="1">
<li>subgradient: slow convergency.</li>
<li>gradient: require differentiable</li>
</ol>
</blockquote>
<p>consider: <span class="math display">\[
\min \phi(x) = f(x) + h(Ax)
\]</span> even <span class="math inline">\(h\)</span> has a simple
proximal mapping, the proximal mapping of <span
class="math inline">\(h(Ax)\)</span> is hard to compute.</p>
<p>Introduce <span class="math inline">\(y = Ax\)</span>, the
Lagrangian: <span class="math display">\[
L(x, y, z) = f(x) + h(y) + z^T (Ax - y)
\]</span> The dual problem: <span class="math display">\[
\max - f^*(-A^T z) - h^*(z)
\]</span></p>
<p><strong>Property of strong convexity</strong>: suppose <span
class="math inline">\(\mu &gt; 0\)</span> is the strong convexity
parameter of <span class="math inline">\(f\)</span>, then its conjugate
<span class="math inline">\(f^*\)</span> is <span
class="math inline">\(\mu\)</span>-smooth and differentiable.</p>
<p><strong>Equality constrained problems</strong>: <span
class="math display">\[
\min f(x) \quad \text{s.t.} \quad Ax = b
\implies
\min f^* (-A^T z) + b^T z
\]</span></p>
<p><strong>Dual subgradient accent</strong>: <span
class="math display">\[
x_{k+1} = \arg\min_x (f(x) + z_k^T Ax)\\
z_{k+1} = z_k + \alpha_k (Ax_{k+1} - y)
\]</span></p>
<p><strong>Separable problem with inequality constraints</strong>: <span
class="math display">\[
\min f_1 (x_1) + f_2 (x_2) \quad \text{s.t.} \quad A_1 x_1 + A_2 x_2
\leq b
\]</span> the dual problem is: <span class="math display">\[
\max -f_1^* (- A_1^T z) - f_2^* (- A_2^T z) - b^T z
\quad \text{s.t.} \quad z \geq 0
\]</span></p>
<p>use <strong>Dual projected gradient accent</strong>: <span
class="math display">\[
x_{k+1} = \arg\min_x (f_1(x_1) + f_2(x_2) + z_k^T (A_1 x_1 + A_2 x_2))\\
z_{k+1} = \Pi_{\mathbb{R}_+^m} (z_k + \alpha_k (A_1 x_{1, k+1} + A_2
x_{2, k+1} - b))
\]</span></p>
<h3 id="dual-proximal-gradient-accent">Dual proximal gradient
accent</h3>
<p><strong>Dual proximal gradient accent</strong>: <span
class="math display">\[
z_{k+1} = \text{prox}_{\alpha h^*} (z_k + \alpha A x_k)
\]</span></p>
<p>operate on original problem: <span class="math display">\[
\begin{aligned}
    x_{k+1} &amp;= \text{prox}_{\alpha f} (x_k - \alpha A^T z_k) \\
    y_{k+1} &amp;= \text{prox}_{\alpha^{-1} h} (z_k/t + A x_{k+1})\\
    z_{k+1} &amp;= z_k + \alpha (Ax_{k+1} - y_{k+1})
\end{aligned}
\]</span></p>
<h3 id="min-max-problems">min max problems</h3>
<p>Consider following: <span class="math display">\[
\min f(x) + h(Ax)
\]</span> the dual problem is: <span class="math display">\[
\min \max f(x) + h(y) + z^T (Ax - y)
\]</span></p>
<p>Therefore, we are solving for <span class="math inline">\(L(x, y,
z)\)</span>’s saddle point.</p>
<p><strong>PHDG</strong>: <span class="math display">\[
\begin{aligned}
    x_{k+1} &amp;= \text{prox}_{\alpha f} (x_k - \alpha A^T z_k) \\
    y_{k+1} &amp;= \text{prox}_{\alpha h} (y_k + \alpha A x_{k+1}) \\
\end{aligned}
\]</span></p>
<h2 id="lecture-15-augmented-lagrangian">Lecture 15: Augmented
Lagrangian</h2>
<p><strong>Augmented Lagrangian</strong>: <span class="math display">\[
L_\rho (x, \lambda) = f(x) + \sum_i \lambda_i c_i(x) + \frac{\rho}{2}
\|c(x)\|^2
\]</span></p>
<p>Typically the algorithm is: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="keyword">not</span> converged:</span><br><span class="line">    x = argmin(L(x, lamb))</span><br><span class="line">    lamb = lamb + rho * c(x)</span><br><span class="line">    rho = rho * beta</span><br></pre></td></tr></table></figure></p>
<h3 id="general-constrained-optimization">General constrained
optimization</h3>
<p><strong>General constrained optimization</strong>: <span
class="math display">\[
\min f(x) \quad \text{s.t.} \quad c_i(x) = 0, c_i(x) + s_i = 0, s_i \geq
0
\]</span></p>
<h2 id="lecture-16-admm">Lecture 16: ADMM</h2>
<p>consider: <span class="math display">\[
\min f(x) + g(z) \quad \text{s.t.} \quad Ax + Bz = c
\]</span></p>
<p>Augmented Lagrangian: <span class="math display">\[
L_\rho (x, z, y) = f(x) + g(z) + y^T (Ax + Bz - c) + \frac{\rho}{2} \|Ax
+ Bz - c\|^2
\]</span></p>
<p>Then, the ADMM algorithm is: <span class="math display">\[
\begin{aligned}
    x_{k+1} &amp;= \arg\min_x L_\rho (x, z_k, y_k) \\
    z_{k+1} &amp;= \arg\min_z L_\rho (x_{k+1}, z, y_k) \\
    y_{k+1} &amp;= y_k + \rho (Ax_{k+1} + Bz_{k+1} - c)
\end{aligned}
\]</span></p>
<h3 id="common-techniques">Common Techniques</h3>
<p>Use linear approximation for <span class="math inline">\(f\)</span>
and <span class="math inline">\(g\)</span>: <span
class="math display">\[
f(x) \approx f(x_k) + \nabla f(x_k)^T (x - x_k) + \frac{1}{2} (x -
x_k)^T H (x - x_k)
\]</span></p>
<p>Many block ADMM: may not converge.</p>
<h3 id="douglas-rachford-splitting">Douglas-Rachford Splitting</h3>
<p>Consider: <span class="math display">\[
\min f(x) = g(x) + h(x)
\]</span></p>
<p><strong>Douglas-Rachford Splitting</strong>: <span
class="math display">\[
\begin{aligned}
    x_{k+1} &amp;= \text{prox}_{\alpha h} (z_k) \\
    y_{k+1} &amp;= \text{prox}_{\alpha g} (2 x_{k+1} - z_k) \\
    z_{k+1} &amp;= z_k + (x_{k+1} - y_{k+1})
\end{aligned}
\]</span></p>
<p>Therefore, we merge 3 steps into one: <span class="math display">\[
z_{k+1} = F(z_k)
\]</span></p>
<p>This is a fixed point iteration, and the convergence is guaranteed if
<span class="math inline">\(F\)</span> is nonexpansive: <span
class="math display">\[
\|F(x) - F(y)\| \le \|x - y\|
\]</span></p>
<p>firmly nonexpansive: <span class="math display">\[
\|F(x) - F(y)\|^2 \le \langle x - y, F(x) - F(y) \rangle
\]</span></p>
<p>In DR: <span class="math display">\[
F(z) = z + \mathrm{prox}_{\alpha h} (2 \mathrm{prox}_{\alpha g} (z) - z)
- \mathrm{prox}_{\alpha h} (z)
\]</span></p>
<p><span class="math inline">\(F\)</span> is firmly nonexpansive if
<span class="math inline">\(g\)</span> and <span
class="math inline">\(h\)</span> are convex.</p>
<h2 id="lecture-17-block-coordinate-descent">Lecture 17: Block
Coordinate Descent</h2>
<h3 id="coordinate-descent">Coordinate Descent</h3>
<p><strong>Coordinate Descent</strong>: <span class="math display">\[
x_i^{k+1} = \arg\min_{x_i} f(x_1^{k+1}, ..., x_{i-1}^{k+1}, x_i,
x_{i+1}^k, ..., x_n^k)
\]</span></p>
<p>will converge? not always. 1. if differentiable and convex, then it
converges. 2. if non-differentiable, then it may not converge.</p>
<p>For example: <span class="math display">\[
f(x) = \frac{1}{2} (x_1^2 + x_2^2) + |x_1 - x_2|
\]</span></p>
<p>A special case is, the non-smooth convex part is separable: <span
class="math display">\[
F(x) = f(x) + \sum_i r_i (x_i)
\]</span> where <span class="math inline">\(f\)</span> is
differentiable. CD will converge.</p>
<p>Challenges: 1. non convex &amp; non smooth problem? 2. non separable
problem: the structure of <span class="math inline">\(f\)</span> is
complex.</p>
<p>Wish: 1. the update is simple 2. guarantee the global convergence</p>
<h3 id="block-coordinate-descent">Block Coordinate Descent</h3>
<p>Consider this problem: <span class="math display">\[
F(x) = f(x_1, ..., x_s) + \sum_i r_i(x_i)
\]</span></p>
<p>updating rule: update a block of variables at each iteration(run a
minimization subroutine).</p>
<p>Divide the variables into blocks: <span class="math display">\[
x = (x_1, x_2, ..., x_s)
\]</span></p>
<p>and the proxy function: <span class="math display">\[
f_i^k(x_i) = f(x_1^k, ... , x_i, ..., x_s^k)
\]</span></p>
<p>Typically, <span class="math inline">\(x_i\)</span> is updated by: 1.
exact minimization: <span class="math display">\[\min f_i^k(x_i) +
r_i(x_i)\]</span> 2. with regularization: <span
class="math display">\[\min f_i^k(x_i) + r_i(x_i) + \frac{L_i^{k-1}}{2}
\|x_i - x_i^k\|^2\]</span> 3. linear approximation: <span
class="math display">\[\min f_i^k(x_i) + \nabla f_i^k(x_i^k)^T (x_i -
x_i^k) + \frac{L_i^{k-1}}{2} \|x_i - x_i^k\|^2 + r_i(x_i)\]</span> every
scheme has its own suitable problems</p>
<h3 id="dual-block-coordinate-ascent">Dual Block Coordinate Ascent</h3>
<p>Original problem: <span class="math display">\[
\min P(w) = \frac{1}{n} \sum_{i=1}^n \phi_i(w^T x_i) + \frac{\lambda}{2}
\|w\|^2
\]</span></p>
<p>Dual problem: <span class="math display">\[
\max_\alpha D(\alpha) =
\frac{1}{n} \sum_{i=1}^n -\phi_i^*(-\alpha_i) - \frac{\lambda}{2}
\|\frac{1}{\lambda n} \sum_{i=1}^n x_i \alpha_i\|^2
\]</span></p>
<p><strong>Stochastic Dual Coordinate Ascent</strong>: 1. randomly
select <span class="math inline">\(i\)</span> 2. update <span
class="math inline">\(\alpha_i\)</span> by exact line search 3. update
<span class="math inline">\(w_t\)</span> 4. terminate if <span
class="math inline">\(\|w_t - w_{t-1}\| &lt; \epsilon\)</span></p>
<h2 id="lecture-18-stochastic-optimization">Lecture 18: Stochastic
Optimization</h2>
<h3 id="stochastic-gradient-descentsgd">Stochastic Gradient
Descent(SGD)</h3>
<p><span class="math display">\[
x_{k+1} = x_k - \alpha_k \nabla f_{s_k} (x_k)
\]</span> where <span class="math inline">\(s_k\)</span> is a random
sample.</p>
<p>We need to ensure the random gradient’s conditional expectation is
the true gradient: <span class="math display">\[
\mathbb{E}[\nabla f_s(x_k)\mid x_k] = \nabla f(x)
\]</span></p>
<p>Mini-batch SGD: <span class="math display">\[
x_{k+1} = x_k - \frac{\alpha_k}{B} \nabla f_{S_k} (x_k)
\]</span> where <span class="math inline">\(B = \mathrm{cord}
S_k\)</span>.</p>
<p>Nesterov’s accelerated SGD: <span class="math display">\[
\begin{aligned}
    y_k &amp;= x_k + \mu_k (x_k - x_{k-1}) \\
    x_{k+1} &amp;= y_k - \alpha_k \nabla f_{s_k} (y_k)
\end{aligned}
\]</span></p>
<h3 id="convergency-of-sgd">Convergency of SGD</h3>
<p>Consider a differentiable, strong convex problem, 1. <span
class="math inline">\(g(x_t, \xi_t)\)</span> is unbiased estimator of
<span class="math inline">\(\nabla f(x_t)\)</span> 2. Variance is
bounded, <span class="math inline">\(\mathbb{E}[\|g(x_t, \xi_t) - \nabla
f(x_t)\|^2] \le \sigma^2 + c_g \|\nabla F(x)\|_2^2\)</span></p>
<p>Then, the convergency rate of SGD is: <span class="math display">\[
E[f(x_k) - f(x^*)] \le \frac{\eta L \sigma_g^e}{2\mu} + (1 - \eta \mu)^k
(f(x_0) - f(x^*))
\]</span></p>
<p>If we only have convexity, instead of strong convexity: <span
class="math display">\[
E[f(x_k) - f(x^*)] \le \frac{E[\|x_0 - x^*\|^2] +
\sigma_g^2\sum_{t=0}^{k-1} \eta_t^2}{2\sum_{t=0}^{k-1} \eta_t}
\]</span></p>
<p>If <span class="math inline">\(\eta_t \approx \sqrt{1/t}\)</span>,
then: <span class="math display">\[
E[f(x_k) - f(x^*)] \approx \frac{\log t}{\sqrt{t}}
\]</span></p>
<h2 id="lecture-19-advanced-stochastic-optimization">Lecture 19:
Advanced Stochastic Optimization</h2>
<h3 id="adagrad">AdaGrad</h3>
<p>Idea: adapt the learning rate for each parameter.</p>
<blockquote>
<p>If some component of the gradient is large, then the learning rate
for this component should be small.</p>
<p>If some component of the gradient is small, then the learning rate
for this component should be large.</p>
</blockquote>
<p>let <span class="math inline">\(g_k = \nabla f_{s_k} (x_k)\)</span>,
and <span class="math display">\[
G_k = \sum_{t=0}^k g_t\odot g_t, \quad (G_k)_i = \sum_{t=0}^k (g_t)_i^2
\]</span></p>
<p>then the update rule is: <span class="math display">\[
\begin{aligned}
    x_{k+1}&amp;= x_k - \frac{\alpha}{\sqrt{G_k + \epsilon}} \odot g_k\\
    G_{k+1}&amp;= G_k + g_k \odot g_k
\end{aligned}
\]</span></p>
<p>Advantage: step size is automatically adjusted.</p>
<p>Disadvantage: the step size will be too small after a long time.</p>
<h3 id="rmsprop">RMSProp</h3>
<p>Idea: use a moving average of the squared gradient. <span
class="math display">\[
M_{k+1} = \beta M_k + (1 - \beta) g_k \odot g_k
\]</span> root mean square: <span class="math display">\[
R_k = \sqrt{M_k + \epsilon}
\]</span></p>
<p><strong>RMSProp</strong>: <span class="math display">\[
\begin{aligned}
    x_{k+1}&amp;= x_k - \frac{\alpha}{R_k} \odot g_k\\
    M_{k+1}&amp;= \beta M_k + (1 - \beta) g_k \odot g_k
\end{aligned}
\]</span></p>
<h3 id="adam">Adam</h3>
<p><strong>Influence of batch size</strong>:</p>
<table>
<thead>
<tr>
<th></th>
<th>small</th>
<th>large</th>
</tr>
</thead>
<tbody>
<tr>
<td>speed for one update (no parallel)</td>
<td>fast</td>
<td>slow</td>
</tr>
<tr>
<td>speed for one update (with parallel)</td>
<td>same</td>
<td>same</td>
</tr>
<tr>
<td>time for one epoch</td>
<td>slow</td>
<td>fast</td>
</tr>
<tr>
<td>gradient</td>
<td>noisy</td>
<td>less noisy</td>
</tr>
<tr>
<td>optimization</td>
<td>better!</td>
<td>worse</td>
</tr>
<tr>
<td>generalization</td>
<td>better!</td>
<td>worse</td>
</tr>
</tbody>
</table>
<p><strong>Adam</strong>: momentum term <span class="math display">\[
S_k = \rho_1 S^{k-1} + (1 - \rho_1) g_k
\]</span></p>
<p>Second order term: <span class="math display">\[
M_k = \rho_2 M^{k-1} + (1 - \rho_2) g_k \odot g_k
\]</span></p>
<p>Bias correction: <span class="math display">\[
\hat{S}_k = \frac{S_k}{1 - \rho_1^k}, \quad \hat{M}_k = \frac{M_k}{1 -
\rho_2^k}
\]</span></p>
<p>Update rule: <span class="math display">\[
x_{k+1} = x_k - \frac{\alpha}{\sqrt{\hat{M}_k} + \epsilon} \odot
\hat{S}_k
\]</span></p>
<p>SGDR: stochastic gradient descent with warm restarts.</p>
<h3 id="sag-saga">SAG, SAGA</h3>
<p>Monte carlo estimates <span class="math inline">\(E[X]\)</span>, if
we can sample another <span class="math inline">\(Y\)</span> is the same
distribution, then we can estimate <span
class="math inline">\(E[X]\)</span> by <span
class="math inline">\(E[Y]\)</span>. <span class="math display">\[
\theta_\gamma = \gamma (X - Y) + E[Y] \implies E[\theta_\gamma] = \gamma
E[X] + (1 - \gamma) E[Y]
\]</span></p>
<ul>
<li>SAG: stochastic average gradient</li>
<li>SAGA</li>
<li>SVRG: stochastic variance reduced gradient</li>
</ul>
<p>First, sample <span class="math inline">\(\nabla
f_{s_k}(x_k)\)</span>, store in memory. <span class="math display">\[
g_i^{k-1} = \nabla f_{s_k}(x_k)
\]</span></p>
<p>and let <span class="math inline">\(\gamma = 1/N\)</span>, we can get
a estimate of gradients: <span class="math display">\[
\theta_\gamma^k = \frac{1}{N} (\nabla f_{s_k} (x_k) - g_{s_k}^{k-1}) +
\sum_{i=1}^N g_i^{k-1}
\]</span></p>
<p><strong>SAG</strong>: <span class="math display">\[
\begin{aligned}
    x_{k+1} &amp;= x_k - \alpha \theta_\gamma^k \\
    g_{s_k}^{k-1} &amp;= \nabla f_{s_k} (x_k) \quad \text{if } s_k
\text{ is sampled}
\end{aligned}
\]</span></p>
<p><strong>SAGA</strong>: let <span class="math inline">\(\gamma =
1\)</span> <span class="math display">\[
\begin{aligned}
    x_{k+1} &amp;= x_k - \alpha_k \left( \nabla f_{s_k} (x^k) -
g_{s_k}^{k-1} + \frac{1}{N} \sum_{i=1}^N g_i^{k-1} \right) \\
    g_{s_k}^{k-1} &amp;= \nabla f_{s_k} (x_k) \quad \text{if } s_k
\text{is sampled}
\end{aligned}
\]</span></p>
<h3 id="svrg">SVRG</h3>
<p><strong>SVRG</strong>: use periodic cache of full gradient to reduce
variance.</p>
<p>Let <span class="math inline">\(\tilde{x}^j\)</span> is <span
class="math inline">\(j\)</span>-th check point, we need: <span
class="math display">\[
\nabla f(\tilde{x}^j) = \frac{1}{n} \sum_{i=1}^n \nabla f_i(\tilde{x}^j)
\]</span> and use <span class="math display">\[
\nu^k = \nabla f_{s_k}(x^k) - (\nabla f_{s_k}(\tilde{x}^j) - \nabla
f(\tilde{x}^j))
\]</span> as a direction.</p>
<p>We can prove that SVRG’s estimate is unbiased.</p>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/archives/">Writing</a></li>
        
          <li><a href="/tags/">Tag</a></li>
        
          <li><a href="/categories/">Category</a></li>
        
          <li><a href="/search/">Search</a></li>
        
          <li><a target="_blank" rel="noopener" href="http://github.com/adversarr">Projects</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#optimization"><span class="toc-number">1.</span> <span class="toc-text">Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-2-convex-set"><span class="toc-number">1.1.</span> <span class="toc-text">Lecture 2: Convex Set</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#common-convex-sets"><span class="toc-number">1.1.1.</span> <span class="toc-text">Common Convex Sets</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#property-of-conv"><span class="toc-number">1.1.2.</span> <span class="toc-text">Property of conv</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#operations-on-convex-sets"><span class="toc-number">1.1.3.</span> <span class="toc-text">Operations on Convex Sets</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dual-cone-generalized-inequalities"><span class="toc-number">1.1.4.</span> <span class="toc-text">Dual Cone &amp; Generalized
Inequalities</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#separating-hyperplane-theorem"><span class="toc-number">1.1.5.</span> <span class="toc-text">Separating Hyperplane
Theorem</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-3-convex-function"><span class="toc-number">1.2.</span> <span class="toc-text">Lecture 3: Convex Function</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#gradients-hessians"><span class="toc-number">1.2.1.</span> <span class="toc-text">Gradients &amp; Hessians</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#definition"><span class="toc-number">1.2.2.</span> <span class="toc-text">Definition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#checking-convexity"><span class="toc-number">1.2.3.</span> <span class="toc-text">checking convexity</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#operations"><span class="toc-number">1.2.4.</span> <span class="toc-text">Operations</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-4-convex-problems"><span class="toc-number">1.3.</span> <span class="toc-text">Lecture 4: Convex Problems</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-5-optimal-conditions"><span class="toc-number">1.4.</span> <span class="toc-text">Lecture 5: Optimal conditions</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#first-order-condition-and-second-order-condition"><span class="toc-number">1.4.1.</span> <span class="toc-text">First Order
Condition and Second Order Condition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#duality"><span class="toc-number">1.4.2.</span> <span class="toc-text">Duality</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#optimal-condition-slater-kkt-licq"><span class="toc-number">1.4.3.</span> <span class="toc-text">Optimal condition: Slater,
KKT, LICQ</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#general-kkt-condition"><span class="toc-number">1.4.3.1.</span> <span class="toc-text">General KKT condition</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-6-gradient-descent"><span class="toc-number">1.5.</span> <span class="toc-text">Lecture 6: Gradient Descent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#more-on-convex-functions"><span class="toc-number">1.5.1.</span> <span class="toc-text">More on convex functions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#line-searching"><span class="toc-number">1.5.2.</span> <span class="toc-text">Line searching</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#non-smooth-problems"><span class="toc-number">1.5.3.</span> <span class="toc-text">Non smooth problems</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-7-subgradients"><span class="toc-number">1.6.</span> <span class="toc-text">Lecture 7: Subgradients</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#definition-of-subgradients-subdifferential"><span class="toc-number">1.6.1.</span> <span class="toc-text">Definition of
Subgradients &amp; Subdifferential</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#computing-subgradients-subdifferential"><span class="toc-number">1.6.2.</span> <span class="toc-text">Computing Subgradients
&amp; Subdifferential</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#optimal-condition"><span class="toc-number">1.6.3.</span> <span class="toc-text">Optimal condition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#subgradient-methods"><span class="toc-number">1.6.4.</span> <span class="toc-text">Subgradient methods</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-8-projected-gradient-descent-conditional-gradient-descent"><span class="toc-number">1.7.</span> <span class="toc-text">Lecture
8: projected gradient descent, conditional gradient descent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#conditional-gradient-descent"><span class="toc-number">1.7.1.</span> <span class="toc-text">Conditional Gradient Descent</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-910-proximal-mapping-proximal-gradient-descent"><span class="toc-number">1.8.</span> <span class="toc-text">Lecture
9&#x2F;10: Proximal Mapping &amp; Proximal Gradient Descent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#definition-of-proximal-mapping"><span class="toc-number">1.8.1.</span> <span class="toc-text">Definition of Proximal
Mapping</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#moreau-decomposition"><span class="toc-number">1.8.2.</span> <span class="toc-text">Moreau decomposition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#proximal-gradient-descent"><span class="toc-number">1.8.3.</span> <span class="toc-text">Proximal Gradient Descent</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#convergency"><span class="toc-number">1.8.3.1.</span> <span class="toc-text">Convergency</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#moreau-envelope"><span class="toc-number">1.8.4.</span> <span class="toc-text">Moreau Envelope</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-11-accelerated-gradient-descent"><span class="toc-number">1.9.</span> <span class="toc-text">Lecture 11: Accelerated
Gradient Descent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#fista"><span class="toc-number">1.9.1.</span> <span class="toc-text">FISTA</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-12-newtons-method"><span class="toc-number">1.10.</span> <span class="toc-text">Lecture 12: Newton’s Method</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-13-quasi-newton-methods"><span class="toc-number">1.11.</span> <span class="toc-text">Lecture 13: Quasi-Newton
Methods</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#secant-equation"><span class="toc-number">1.11.1.</span> <span class="toc-text">Secant Equation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sr1"><span class="toc-number">1.11.2.</span> <span class="toc-text">SR1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bfgs"><span class="toc-number">1.11.3.</span> <span class="toc-text">BFGS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dfp"><span class="toc-number">1.11.4.</span> <span class="toc-text">DFP</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lbfgs"><span class="toc-number">1.11.5.</span> <span class="toc-text">LBFGS</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-14-dual-ascent"><span class="toc-number">1.12.</span> <span class="toc-text">Lecture 14: Dual Ascent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#dual-proximal-gradient-accent"><span class="toc-number">1.12.1.</span> <span class="toc-text">Dual proximal gradient
accent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#min-max-problems"><span class="toc-number">1.12.2.</span> <span class="toc-text">min max problems</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-15-augmented-lagrangian"><span class="toc-number">1.13.</span> <span class="toc-text">Lecture 15: Augmented
Lagrangian</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#general-constrained-optimization"><span class="toc-number">1.13.1.</span> <span class="toc-text">General constrained
optimization</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-16-admm"><span class="toc-number">1.14.</span> <span class="toc-text">Lecture 16: ADMM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#common-techniques"><span class="toc-number">1.14.1.</span> <span class="toc-text">Common Techniques</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#douglas-rachford-splitting"><span class="toc-number">1.14.2.</span> <span class="toc-text">Douglas-Rachford Splitting</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-17-block-coordinate-descent"><span class="toc-number">1.15.</span> <span class="toc-text">Lecture 17: Block
Coordinate Descent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#coordinate-descent"><span class="toc-number">1.15.1.</span> <span class="toc-text">Coordinate Descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#block-coordinate-descent"><span class="toc-number">1.15.2.</span> <span class="toc-text">Block Coordinate Descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dual-block-coordinate-ascent"><span class="toc-number">1.15.3.</span> <span class="toc-text">Dual Block Coordinate Ascent</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-18-stochastic-optimization"><span class="toc-number">1.16.</span> <span class="toc-text">Lecture 18: Stochastic
Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#stochastic-gradient-descentsgd"><span class="toc-number">1.16.1.</span> <span class="toc-text">Stochastic Gradient
Descent(SGD)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#convergency-of-sgd"><span class="toc-number">1.16.2.</span> <span class="toc-text">Convergency of SGD</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lecture-19-advanced-stochastic-optimization"><span class="toc-number">1.17.</span> <span class="toc-text">Lecture 19:
Advanced Stochastic Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#adagrad"><span class="toc-number">1.17.1.</span> <span class="toc-text">AdaGrad</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rmsprop"><span class="toc-number">1.17.2.</span> <span class="toc-text">RMSProp</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#adam"><span class="toc-number">1.17.3.</span> <span class="toc-text">Adam</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sag-saga"><span class="toc-number">1.17.4.</span> <span class="toc-text">SAG, SAGA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#svrg"><span class="toc-number">1.17.5.</span> <span class="toc-text">SVRG</span></a></li></ol></li></ol></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&text=A short summary to Optimization Theory."><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&title=A short summary to Optimization Theory."><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&is_video=false&description=A short summary to Optimization Theory."><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=A short summary to Optimization Theory.&body=Check out this article: https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&title=A short summary to Optimization Theory."><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&title=A short summary to Optimization Theory."><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&title=A short summary to Optimization Theory."><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&title=A short summary to Optimization Theory."><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&name=A short summary to Optimization Theory.&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://adversarr.github.io/2024/06/20/optimizer/optimizer_final/&t=A short summary to Optimization Theory."><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2020-2024
    Adversarr
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/tags/">Tag</a></li><!--
     --><!--
       --><li><a href="/categories/">Category</a></li><!--
     --><!--
       --><li><a href="/search/">Search</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/adversarr">Projects</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
